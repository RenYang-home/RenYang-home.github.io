<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<title>YANG, REN</title>
</head>
<body>

<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#patents">Patents</a> 
<a href="#awards">Awards</a> 
<a href="#tutorials">Tutorials</a> 
<a href="#workshops">Workshops</a>
<a href="#services">Services</a> 
<a href="#teaching">Teaching</a>
</div>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<div id="toptitle">
<h1>YANG, Ren</h1>
</div>

<table class="imgtable"><tr><td>
<a href="./"><img src="./files/yangren.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">YANG, Ren</font></a><br />
<i> Doctoral Student </i>
<br /><br />
<a href="http://www.vision.ee.ethz.ch/en/">Computer Vision Laboratory</a><br />
Dept. of Information Technology and Electrical Engineering, ETH Zurich<br />
Sternwartstrasse 7, 8092 Zurich, Switzerland<br />
<br />
Email: <i>ren.yang@vision.ee.ethz.ch</i><br />
<br />
[<a href="https://scholar.google.ch/citations?user=3NgkOp0AAAAJ&hl=en" target="_blank">Google Scholar</a>]
</p>
</td></tr></table>

<h2>Biography</h2>
<p style="text-align:justify">I am a Doctoral (PhD) student at the <a href="http://www.vision.ee.ethz.ch/en/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html">ETH Zurich</a>, Switzerland, under the supervision of <a href="https://www.vision.ee.ethz.ch/en/members/get_member.cgi?id=1#/">Prof. Dr. Luc Van Gool</a> and <a href="http://www.vision.ee.ethz.ch/~timofter/">Dr. Radu Timofte</a>. My research interests include learned video compression and quality enhancement. I obtained the M.Sc. degree in 2019 at the <a href="http://www.buaamc2.net/">MC^2 Lab</a>, <a href="http://ev.buaa.edu.cn/">Beihang University</a>, P.R. China, under the supervision of <a href="http://www.buaamc2.net/">Prof. Dr. Mai Xu</a>, and obtained the B.Sc. degree at the same university in 2016. My Master Thesis got the <b>Winner of <a href= "https://threeminutethesis.uq.edu.au/">Three Minute Thesis Competition </a></b> at IEEE ICME 2019 [<a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Certificate</a>], and won the <b>Outstanding Master Thesis Award</b> of <a href="https://www.cie-info.org.cn/">Chinese Institute of Elecronics</a> [<a href= "https://www.cie.org.cn/site/content/3519.html">News</a>] [<a href= "https://RenYang-home.github.io/papers/CIE_master.jpg">Certificate</a>]. </p>

<p style="text-align:justify">I worked as a Research Intern (2018-2019) in the <a href="https://www.microsoft.com/en-us/research/group/internet-media/">Intelligent Multimedia Group</a>, <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, under the supervision of Dr. Xiaoyan Sun and <a href="https://www.microsoft.com/en-us/research/people/wezeng/">Prof. Dr. Wenjun Zeng</a>. I won the <b>Award of Excellence</b> at Microsoft Research during my internship [<a href= "https://RenYang-home.github.io/papers/MSRaward.jpg">Certificate</a>].</p>

<h2>News</h2>
<ul>
<li>I will serve as a Guest Speaker for the <a href= "https://guolu-home.github.io/cvpr21-tutorial">Data Compression Tutorial</a> at CVPR 2021.</li>
<li>One paper is accepted to <b>CVPR</b> 2021 <font color="red"><b>(Oral)</b></font>. [<a href= "http://buaamc2.net/pdf/cvpr21hesic.pdf">Paper</a>] [<a href= "https://github.com/ywz978020607/HESIC">Code</a>]</li>
<li>Our <b>US Patent</b> for multi-frame video enhancement has been published. [<a href= "https://patents.google.com/patent/US20200404340A1/en">Google Patent</a>]
<li>I serve as a <b>Senior Program Committee (SPC)</b> member for IJCAI 2021.
<li>We organize the <b>video enhancement challenges</b> at the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">NTIRE workshop</a> in CVPR 2021.</li>
<!--   <ul>
          <li>Quality enhancement of heavily compressed videos: <a href= "https://competitions.codalab.org/competitions/28033">Track 1 Fixed QP, Fidelity</a> <font color="red"><b>started!</b></font></li>
          <li>Quality enhancement of heavily compressed videos: <a href= "https://competitions.codalab.org/competitions/28034">Track 2 Fixed QP, Perceptual</a> <font color="red"><b>started!</b></font></li>
          <li>Quality enhancement of heavily compressed videos: <a href= "https://competitions.codalab.org/competitions/28035">Track 3 Fixed bit-rate, Fidelity</a> <font color="red"><b>started!</b></font></li>  
  </ul> -->
<li>Talk on Learning-based Video Compression, Dec. 23, 2020 [<a href= "http://RenYang-home.github.io/files/zhidongxi_1223.pdf">Slide</a>] [<a href= "https://apposcmf8kb5033.h5.xiaoeknow.com/v1/course/alive/l_5fd8a285e4b0231ba88ce9fc?app_id=appoSCMf8kb5033&is_redirect=1&scene=%E5%88%86%E4%BA%AB&share_type=5&share_user_id=u_5eb92d577fec0_f0a8lSsIPJ&type=2">Video record</a> (in Chinese)]</li>
<li>One paper is accepted to IEEE Journal of Selected Topics in Signal Processing (<b>J-STSP</b>). [<a href= "https://ieeexplore.ieee.org/abstract/document/9288876">Paper</a>] [<a href= "https://github.com/RenYang-home/RLVC">Code</a>]</li>
<li>We deliver a <b>Tutorial</b> on Learned Image and Video Compression at IEEE VCIP 2020. [<a href= "https://ieeexplore.ieee.org/abstract/document/9301828">Abstract</a>] [<a href= "http://RenYang-home.github.io/papers/VCIP_Tutorial.pdf">Slide</a>] [<a href= "https://www.polybox.ethz.ch/index.php/s/PSmRYBTyvljzkbm">Video record</a>]</li>
<li>I supervise a <a href="https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Master's Semester Thesis</a> on learned image compression at ETH Zurich. 
<!--   [<a href= "https://github.com/YannickStruempler/LearnedJPEG">Code</a>] -->
<li>Our open source deep video compression project OpenDVC is on-line. [<a href="https://github.com/RenYang-home/OpenDVC">Code</a>] [<a href= "https://arxiv.org/abs/2006.15862">Technical report</a>] </li>
<!-- <li>One patent for single frame video enhancement is <b>granted</b>. [<a href= "https://renyang-home.github.io/papers/patent_sfqe.pdf">Certificate</a>] [<a href= "https://patents.google.com/patent/CN107481209A/zh?q=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%88%96%E8%A7%86%E9%A2%91&oq=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%88%96%E8%A7%86%E9%A2%91">Google Patent</a>]</li> -->
<li>One paper is accepted to <b>CVPR</b> 2020. [<a href= "http://arxiv.org/abs/2003.01966">Paper</a>] [<a href= "https://github.com/RenYang-home/HLVC">Code</a>]</li>
<li>One paper (collaborated with <a href="https://jiaxinlu-home.github.io/">my wife</a>) is accepted to IEEE Trans. on Image Processing (<b>T-IP</b>). [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9025769">Paper</a>] [<a href= "https://github.com/RenYang-home/Natural-Scene-Memorability">Code</a>] [<a href= "https://github.com/JiaxinLu-home/Natural-Scene-Memorability-Dataset">Dataset</a>]</li>
<li>I won the <b>2019 Outstanding Master Thesis Award</b> of <a href="https://www.cie-info.org.cn/">Chinese Institute of Elecronics</a>. [<a href= "https://www.cie.org.cn/site/content/3519.html">News</a>]</li>
<li>One paper is accepted to <b>ICCV</b> 2019 <font color="red"><b>(Oral)</b></font></a>. [<a href= "http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Wavelet_Domain_Style_Transfer_for_an_Effective_Perception-Distortion_Tradeoff_in_ICCV_2019_paper.pdf">Paper</a>] [<a href="https://github.com/cindydeng1991/Wavelet-Domain-Style-Transfer-for-an-Effective-Perception-distortion-Tradeoff-in-Single-Image-Super-">Code</a>] </li>
<li>One paper is accepted to IEEE Transactions on Pattern Analysis and Machine Intelligence (<b>T-PAMI</b>). [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855019">Paper</a>] [<a href="https://github.com/RyanXingQL/MFQEv2.0">Code</a>] </li>
<li>I got the <b>Winner of <a href= "https://threeminutethesis.uq.edu.au/">Three Minute Thesis Competition</a></b> at <b>IEEE ICME</b> 2019. [<a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Certificate</a>]</li>

</ul> 

<a id="publications" class="achor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">

<tr>
<td><img class="proj_thumb" src="./papers/CVPR2021.png" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Deep Homography for Efficient Stereo Image Compression</p>
<p class="pub_author">Xin Deng,&nbsp;Wenzhe Yang,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Enpeng Liu,&nbsp;Qianhan Feng and Radu Timofte.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2021. <font color="red"><b>(Oral)</b></font> <br> 
[<a href= "http://buaamc2.net/pdf/cvpr21hesic.pdf">Paper</a>] [<a href= "https://github.com/ywz978020607/HESIC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/JSTSP.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Fabian Mentzer,&nbsp;Luc Van Gool and Radu Timofte.<br>
IEEE Journal of Selected Topics in Signal Processing</i> (<b>J-STSP</b>), 2021. <br> 
[<a href= "https://ieeexplore.ieee.org/abstract/document/9288876">Paper</a>] [<a href= "https://github.com/RenYang-home/RLVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/AIM20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning to Improve Image Compression without Changing the Standard Decoder</p>
<p class="pub_author">Yannick Strümpler,&nbsp;<u><b>Ren Yang</b></u> and Radu Timofte.<br>
European Conference on Computer Vision Workshops</i> (<b>ECCVW</b>), 2020. <br> 
[<a href= "https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Paper</a>]
</p> </td>
</tr>
  
<tr>
<td><img class="proj_thumb" src="./papers/CVPR20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Fabian Mentzer,&nbsp;Luc Van Gool and Radu Timofte.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2020. <br> 
[<a href= "http://arxiv.org/abs/2003.01966">Paper</a>] [<a href= "https://github.com/RenYang-home/HLVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/TIP20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Understanding and Predicting the Memorability of Outdoor Natural Scenes</p>
<p class="pub_author">Jiaxin Lu,&nbsp;Mai Xu,&nbsp;<u><b>Ren Yang</b></u> and Zulin Wang.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2020. <br> 
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9025769">Paper</a>] [<a href= "https://github.com/RenYang-home/Natural-Scene-Memorability">Code</a>] [<a href= "https://github.com/JiaxinLu-home/Natural-Scene-Memorability-Dataset">Dataset</a>] [<a href= "https://dl.acm.org/doi/pdf/10.1145/3267799.3267802">Conference paper (EE-USAD 2018) <font color="red"><b>(Oral)</b></font></a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ICCV19.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Wavelet Domain Style Transfer for an Effective Perception-distortion Tradeoff in Single Image Super-Resolution</p>
<p class="pub_author">Xin Deng,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Mai Xu and Pier Luigi Dragotti.<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2019. <font color="red"><b>(Oral)</b></font><br>
[<a href= "http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Wavelet_Domain_Style_Transfer_for_an_Effective_Perception-Distortion_Tradeoff_in_ICCV_2019_paper.pdf">Paper</a>] [<a href="https://github.com/cindydeng1991/Wavelet-Domain-Style-Transfer-for-an-Effective-Perception-distortion-Tradeoff-in-Single-Image-Super-">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ICME19.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Quality-Gated Convolutional LSTM for Enhancing Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Xiaoyan Sun,&nbsp;Mai Xu and Wenjun Zeng.<br>
IEEE International Conference on Multimedia and Expo</i> (<b>ICME</b>), 2019. <font color="red"><b>(Oral)</b></font><br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784864">Paper</a>] [<a href="https://github.com/ryangchn/QG-ConvLSTM">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/PAMI19.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video</p>
<p class="pub_author">Zhengyu Guan,&nbsp;Qunliang Xing,&nbsp;Mai Xu,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Tie Liu and Zulin Wang.<br>
IEEE Transactions on Pattern Analysis and Machine Intelligence</i> (<b>T-PAMI</b>), 2019. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855019">Paper</a>] [<a href="https://github.com/RyanXingQL/MFQEv2.0">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/DCC19.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">A Deep Learning Approach for Multi-Frame In-Loop Filter of HEVC</p>
<p class="pub_author">Tianyi Li,&nbsp;Mai Xu,&nbsp;Ce Zhu,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Zulin Wang and Zhenyu Guan.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2019. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736997">Paper</a>] [<a href="https://github.com/tianyili2017/MultiFrame-InLoop-Filter">Code</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712730">Conference paper (DCC 2019) <font color="red"><b>(Oral)</b></font></a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/CVPR18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Multi-Frame Quality Enhancement for Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu, &nbsp;Zulin Wang and Tianyi Li.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2018. <br>
[<a href= "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.pdf">Paper</a>] [<a href="https://github.com/ryangBUAA/MFQE">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/TIP18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Reducing Complexity of HEVC: A Deep Learning Approach</p>
<p class="pub_author">Mai Xu,&nbsp;Tianyi Li,&nbsp;Zulin Wang,&nbsp;Xin Deng,&nbsp;<u><b>Ren Yang</b></u> and Zhenyu Guan.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2018. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384310">Paper</a>] [<a href="https://github.com/tianyili2017/HEVC-Complexity-Reduction">Code</a>]</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/CSVT18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Enhancing Quality for HEVC Compressed Videos</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Tie Liu,&nbsp;Zulin Wang and Zhenyu Guan.<br>
IEEE Transactions on Circuits and Systems for Video Technology</i> (<b>T-CSVT</b>), 2018. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450025">Paper</a>] [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019299">Conference paper (ICME 2017) <font color="red"><b>(Oral)</b></font></a>]</p> </td>
</tr>

<!-- <tr>
<td><img class="proj_thumb" src="./papers/ICME17.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Decoder-side HEVC quality enhancement with scalable convolutional neural network</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu and Zulin Wang.<br>
IEEE International Conference on Multimedia and Expo</i> (<b>ICME</b>), 2017. <font color="red"><b>(Oral)</b></font><br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019299">Paper</a>]</p> </td>
</tr> -->

<tr>
<td><img class="proj_thumb" src="./papers/TBC18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Saliency-Guided Complexity Control for HEVC Decoding</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Zulin Wang,&nbsp;Yiping Duan and Xiaoming Tao.<br>
IEEE Transactions on Broadcasting</i> (<b>T-BC</b>), 2018.<br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281502">Paper</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552864">Conference paper (ICME 2016)</a>]</p> </td>
</tr>

</table>

<a id="patents" class="achor"></a>
<h2>Patents</h2>
<ul>
<li><b>Multi-frame quality enhancement method and device for lossy compressed video</b> <br>
  WO2019154152A1 [<a href= "https://patents.google.com/patent/WO2019154152A1/en">Google Patent</a>] <br>
  US20200404340A1, 2020 [<a href= "https://patents.google.com/patent/US20200404340A1/en">Google Patent</a>] <br>
  CN108307193B, 2018 [<a href= "https://patents.google.com/patent/CN108307193B/zh">Google Patent</a>]  [<a href= "RenYang-home.github.io/papers/patent_MFQE.pdf">Certificate</a>] <br>
</li>
</ul>
<ul>
<li><b>Deep learning method-based block segmentation coding complexity optimization method and device</b> <br>
  WO2019179523A1 [<a href= "https://patents.google.com/patent/WO2019179523A1/en">Google Patent</a>] <br>
  CN108495129B, 2019 [<a href= "https://patents.google.com/patent/CN108495129B/zh">Google Patent</a>] [<a href= "RenYang-home.github.io/papers/patent_CTU.pdf">Certificate</a>] <br>
   </li>
</ul>
<ul>
<li><b>A CNN-based method for image and video enhancement</b><br>
  CN107481209B, 2020 [<a href= "https://patents.google.com/patent/CN107481209A/zh">Google Patent</a>] [<a href= "RenYang-home.github.io/papers/patent_sfqe.pdf">Certificate</a>]<br>
  </li>
</ul>
<ul>
<li><b>A saliency-guided method for complexity control of HEVC decoding</b> <br>
  CN106210717B, 2017 [<a href= "https://patents.google.com/patent/CN106210717A/en?oq=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E6%98%BE%E8%91%97%E6%80%A7%E7%9A%84HEVC%E8%A7%A3%E7%A0%81%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95">Google Patent</a>] [<a href= "RenYang-home.github.io/papers/patent_sgcc.pdf">Certificate</a>] <br>
  </li>
</ul>

<a id="awards" class="achor"></a>
<h2>Awards</h2>
<ul>
<li><b>Winner of <a href= "https://threeminutethesis.uq.edu.au/">Three Minute Thesis Competition</a>, IEEE ICME 2019</b>. [<a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Certificate</a>]</li>
<li><b>2019 Outstanding Master Thesis Award</b> of <a href="https://www.cie-info.org.cn/">Chinese Institute of Elecronics</a>. [<a href= "https://www.cie.org.cn/site/content/3519.html">News</a>] [<a href= "https://RenYang-home.github.io/papers/CIE_master.jpg">Certificate</a>]</li>
<li><b>Award of Excellence</b> at Microsoft Research. [<a href= "https://RenYang-home.github.io/papers/MSRaward.jpg">Certificate</a>]</li>
<li><b>TOP 10</b> Graduate Students Award, Beihang University. [<a href= "https://RenYang-home.github.io/papers/Top10.jpg">Certificate</a>]</li>
<li>National Scholarship, P.R. China. [<a href= "https://RenYang-home.github.io/papers/guojiang.jpg">Certificate</a>]</li>
</ul>

<!-- Tutorials -->
<a id="tutorials" class="anchor"></a>
<h2>Tutorials</h2> 
<ul>
<li>CVPR 2021: Learning for Visual Data Compression [<a href= "https://guolu-home.github.io/cvpr21-tutorial">Tutorial homepage</a>]
<li>IEEE VCIP 2020: Learned Image and Video Compression with Deep Neural Networks. [<a href= "https://ieeexplore.ieee.org/abstract/document/9301828">Abstract</a>] [<a href= "http://RenYang-home.github.io/papers/VCIP_Tutorial.pdf">Slide</a>] [<a href= "https://www.polybox.ethz.ch/index.php/s/PSmRYBTyvljzkbm">Video record</a>]</li>
</ul>

<!-- Workshops -->
<a id="workshops" class="anchor"></a>
<h2>Workshops</h2> 
<ul>
<li><a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">New Trends in Image Restoration and Enhancement (NTIRE) workshop</a>, in conjunction with CVPR 2021.</li>
</ul>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>

<p>Senior Program Commitee (SPC) Member: </p>
<ul>
  <li>International Joint Conference on Artificial Intelligence (IJCAI 2021)</li>
</ul>

<p>Journal Reviewer: </p>
<ul>

<li>International Journal on Computer Vision (IJCV)</li>
<li>IEEE Transactions on Image Processing (T-IP)</li>
<li>IEEE Journal of Selected Topics in Signal Processing (J-STSP)</li>
<li>IEEE Transactions on Multimedia (T-MM)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT)</li>
<li>IEEE Access</li>
<li>Signal Processing: Image Communication</li>
<li>Neurocomputing</li>

</ul>
<p>Conference Reviewer: </p>
<ul>
<li>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2021)</li>
<li>IEEE International Conference on Computer Vision (ICCV 2021)</li>
<li>European Conference on Computer Vision (ECCV 2020)</li>
<li>International Joint Conference on Artificial Intelligence (IJCAI 2021)</li>
<li>Asian Conference on Computer Vision (ACCV 2020)</li>
<li>IEEE/CIC International Conference on Communications in China (ICCC 2018)</li>
</ul>

<!-- Teaching -->
<a id="teaching" class="anchor"></a>
<h2>Teaching</h2> 
<ul>
<li>Supervisor: <a href="https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Master's Semester Thesis</a> on learned image compression, ETH Zurich (Spring 2020) </li>
<li>Teaching Assistant: Digital Image Processing, Beihang University (Spring 2017) </li>
</ul>

<div id="footer">
</div>

</div>
</div>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5y5sm64rjm3&amp;m=0&amp;c=ff0000&amp;cr1=ff0000&amp;f=arial&amp;l=33" async="async"></script>
</body>
</html>
