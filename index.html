<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="files/jemdoc.css" type="text/css" />
<title>Dr. Ren Yang</title>
</head>
<body>

<div class="menu"> <a href="#home">Home</a> 
<a href="#publications">Publications</a> 
<a href="#patents">Patents</a> 
<a href="#awards">Awards</a> 
<a href="#tutorials">Tutorials</a> 
<a href="#workshops">Workshops</a>
<a href="#services">Services</a> 
<a href="#teaching">Teaching</a>
</div>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 
<div id="toptitle">
<h1>Dr. Ren Yang</h1>
</div>

<table class="imgtable"><tr><td>
<a href="./"><img src="./files/yangren.jpg" alt="" height="200px" /></a>&nbsp;</td>
<td align="left"><p><a href="./"><font size="4">Ren Yang, Dr. sc. ETH Z端rich</font></a><br />
<i>  </i>
<br />
Senior Researcher<br />
ISP & AI Codec Group, SenseTime Research<br />
<br />
<i> </i>

Email: <i>yangren@sensetime.com, r.yangchn@gmail.com</i><br />
<br />
[<a href="https://scholar.google.ch/citations?user=3NgkOp0AAAAJ&hl=en" target="_blank">Google Scholar</a>] [<a href="https://github.com/RenYang-home" target="_blank">Github</a>] [<a href="https://linkedin.com/in/ren-yang-56221b108" target="_blank">LinkedIn</a>]
</p>
</td></tr></table>

<h2>Biography</h2>
<p style="text-align:justify">I join <a href="https://www.sensetime.com/en">SenseTime</a> as a Senior Researcher on ISP & AI Codec. I obtained the Doctor of Sciences (Dr. sc. ETH Z端rich) degree at the <a href="http://www.vision.ee.ethz.ch/en/">Computer Vision Lab</a>, <a href="https://ethz.ch/en.html">ETH Zurich</a>, Switzerland, under the supervision of <a href="https://www.vision.ee.ethz.ch/en/members/get_member.cgi?id=1#/">Prof. Dr. Luc Van Gool</a> and <a href="http://www.vision.ee.ethz.ch/~timofter/">Prof. Dr. Radu Timofte</a>, and received the <a href= "http://RenYang-home.github.io/papers/CSC.jpg">Chinese Government Award for Outstanding Self-financed Students Abroad</a>. During my doctoral studies, I also worked as a Ph.D. researcher at <a href="https://trace.ethz.ch/">Toyota Research on Automated Cars in Europe (TRACE)</a>. Before that, I was a Research Intern (with  <a href= "https://RenYang-home.github.io/papers/MSRaward.jpg">Award of Excellence</a>) at the <a href="https://www.microsoft.com/en-us/research/group/internet-media/">Intelligent Multimedia Group</a>, <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>. I obtained the M.Sc. degree in 2019 at the <a href="http://www.buaamc2.net/">MC^2 Lab</a>, <a href="http://ev.buaa.edu.cn/">Beihang University</a>, P.R. China, and the B.Sc. degree at the same university in 2016. My Master Thesis is awarded the  <a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Winner of Three Minute Thesis Competition</a> at IEEE ICME 2019, and the <a href= "https://RenYang-home.github.io/papers/CIE_master.jpg">Outstanding Master Thesis</a> of <a href="https://www.cie.org.cn/list_43/3519.html">Chinese Institute of Electronics</a>. </p>

<p style="text-align:justify">I am a <a href= "http://RenYang-home.github.io/papers/session_chair.png">Session Chair</a> at <a href="https://ijcai-22.org/">IJCAI 2022</a>, a <a href= "http://RenYang-home.github.io/papers/IJCAI_SPC.pdf">Senior Program Committee (SPC) Member</a> at <a href="https://ijcai-21.org/">IJCAI 2021</a>, a co-organizer of <a href= "https://cvlai.net/ntire/2023/">NTIRE 2023</a> (CVPR), <a href= "https://data.vision.ee.ethz.ch/cvl/aim22/">AIM 2022</a> (ECCV), <a href= "https://data.vision.ee.ethz.ch/cvl/ntire22/">NTIRE 2022</a> (CVPR) and <a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">NITRE 2021</a>  (CVPR) Workshops, a co-organizer/speaker of Tutorials on deep data compression at ACM MM 2021, CVPR 2021 and VCIP 2020.</p>
    
<h2>News</h2>
<ul>
<li>I received the <b>Chinese Government Award for Outstanding Self-financed Students Abroad (10,000 USD)</b>. [<a href= "http://RenYang-home.github.io/papers/CSC.jpg">Certificate</a>]
<li>One paper is accepted to IEEE Transactions on Circuits and Systems for Video Technology (<b>T-CSVT</b>). [<a href= "https://ieeexplore.ieee.org/abstract/document/10061473">Paper</a>] [<a href= "https://github.com/eecoder-dyf/MASIC">Code</a>]
<li>I am a  co-organizer of the <a href= "https://cvlai.net/ntire/2023/">NTIRE Workshop</a> at CVPR 2023.
<li>One paper is accepted to IEEE Transactions on Circuits and Systems for Video Technology (<b>T-CSVT</b>). [<a href= "https://ieeexplore.ieee.org/abstract/document/9950550">Paper</a>] [<a href= "https://github.com/RenYang-home/ALVC">Code</a>]
<li>I serve as a <b>Session Chair</b> at the Computer Vision Session of IJCAI 2022.
<li>One paper is accepted to <b>ECCV</b> 2022. [<a href= "https://arxiv.org/abs/2112.04267">Paper</a>] [<a href= "https://github.com/YannickStruempler/inr_based_compression">Code</a>]
<li>We organize the <a href="https://github.com/RenYang-home/AIM22_CompressSR">Challenge on Super-Resolution of Compressed Image and Video</a> at the <a href= "https://data.vision.ee.ethz.ch/cvl/aim22/">AIM workshop</a> in ECCV 2022. [<a href= "https://arxiv.org/abs/2208.11184">Report</a>]</li>
<li>One paper is accepted to <b>IJCAI</b> 2022 <font color="red"><b>(Oral)</b></font>. [<a href= "https://arxiv.org/abs/2109.03082">Paper</a>] [<a href= "https://github.com/RenYang-home/PLVC">Code</a>]</li>
<li>We organize the <a href= "https://github.com/RenYang-home/NTIRE22_VEnh_SR">Video Super-Resolution and Enhancement Challenge</a> at the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire22/">NTIRE workshop</a> in CVPR 2022. [<a href= "http://arxiv.org/abs/2204.09314">Report</a>] </li>
<li>I supervise a <b>Master's Thesis</b> on learned image compression at ETH Zurich. [<a href="https://arxiv.org/abs/2112.04267">Paper</a>] [<a href= "https://github.com/YannickStruempler/inr_based_compression">Code</a>]
<li>We organize the <b>Tutorial on Deep Learning for Visual Data Compression</b> at ACM MM 2021. [<a href= "https://2021.acmmm.org/tutorials">Tutorial page</a>]</li>
<li>I serve as a Guest Speaker for the <b>Tutorial on Deep Learning for Visual Data Compression</b> at CVPR 2021. [<a href= "https://guolu-home.github.io/cvpr21-tutorial">Slides</a>]</li>
<li>We organize the <a href= "https://github.com/RenYang-home/NTIRE21_VEnh">Video Enhancement Challenge</a> at the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">NTIRE workshop</a> in CVPR 2021. [<a href= "https://arxiv.org/abs/2104.10782">Dataset</a>] [<a href= "https://arxiv.org/abs/2104.10781">Methods</a>]</li>
<li>I am selected in the Finalist of the <a href="https://www.qualcomm.com/research/research/university-relations/innovation-fellowship/2021-europe">Qualcomm Innovation Fellowship Europe 2021</a>.</li>
<li>One paper is accepted to <b>CVPR</b> 2021 <font color="red"><b>(Oral)</b></font>. [<a href= "https://openaccess.thecvf.com/content/CVPR2021/papers/Deng_Deep_Homography_for_Efficient_Stereo_Image_Compression_CVPR_2021_paper.pdf">Paper</a>] [<a href= "https://github.com/ywz978020607/HESIC">Code</a>]</li>
<li>Our <b>US Patent</b> for multi-frame video enhancement has been <b>Granted</b>. [<a href= "https://patents.google.com/patent/US20200404340A1/en">Google Patent</a>]
<li>I serve as a <b>Senior Program Committee (SPC)</b> member for IJCAI 2021. [<a href= "http://RenYang-home.github.io/papers/IJCAI_SPC.pdf">Certificate</a>]
<!-- <li>Talk on Learning-based Video Compression, Dec. 23, 2020 [<a href= "http://RenYang-home.github.io/files/zhidongxi_1223.pdf">Slide</a>] [<a href= "https://apposcmf8kb5033.h5.xiaoeknow.com/v1/course/alive/l_5fd8a285e4b0231ba88ce9fc?app_id=appoSCMf8kb5033&is_redirect=1&scene=%E5%88%86%E4%BA%AB&share_type=5&share_user_id=u_5eb92d577fec0_f0a8lSsIPJ&type=2">Video record</a> (in Chinese)]</li> -->
<li>One paper is accepted to IEEE Journal of Selected Topics in Signal Processing (<b>J-STSP</b>). [<a href= "https://ieeexplore.ieee.org/abstract/document/9288876">Paper</a>] [<a href= "https://github.com/RenYang-home/RLVC">Code</a>]</li>
<li>We deliver a <b>Tutorial</b> on Learned Image and Video Compression at IEEE VCIP 2020. [<a href= "https://ieeexplore.ieee.org/abstract/document/9301828">Abstract</a>] [<a href= "http://RenYang-home.github.io/papers/VCIP_Tutorial.pdf">Slide</a>] [<a href= "https://www.polybox.ethz.ch/index.php/s/PSmRYBTyvljzkbm">Video record</a>]</li>
<li>I supervise a <b>Master's Semester Project</b> on learned image compression at ETH Zurich. [<a href="https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Paper</a>] [<a href="https://github.com/YannickStruempler/LearnedJPEG">Code</a>]</li>
<!--   [<a href= "https://github.com/YannickStruempler/LearnedJPEG">Code</a>] -->
<!-- <li>Our open source deep video compression project OpenDVC is on-line. [<a href="https://github.com/RenYang-home/OpenDVC">Code</a>] [<a href= "https://arxiv.org/abs/2006.15862">Technical report</a>] </li> -->
<!-- <li>One patent for single frame video enhancement is <b>granted</b>. [<a href= "https://renyang-home.github.io/papers/patent_sfqe.pdf">Certificate</a>] [<a href= "https://patents.google.com/patent/CN107481209A/zh?q=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%88%96%E8%A7%86%E9%A2%91&oq=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9B%BE%E5%83%8F%E6%88%96%E8%A7%86%E9%A2%91">Google Patent</a>]</li> -->
<li>One paper is accepted to <b>CVPR</b> 2020. [<a href= "http://arxiv.org/abs/2003.01966">Paper</a>] [<a href= "https://github.com/RenYang-home/HLVC">Code</a>]</li>
<li>One paper is accepted to IEEE Transactions on Image Processing (<b>T-IP</b>). [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9025769">Paper</a>] [<a href= "https://github.com/RenYang-home/Natural-Scene-Memorability">Code</a>] [<a href= "https://github.com/JiaxinLu-home/Natural-Scene-Memorability-Dataset">Dataset</a>]</li>
<li>My Master Thesis is awarded the <b>2019 Outstanding Master Thesis</b> of <a href="https://www.cie.org.cn/list_43/3519.html">Chinese Institute of Elecronics</a>. [<a href= "https://RenYang-home.github.io/papers/CIE_master.jpg">Certificate</a>]</li>
<li>One paper is accepted to <b>ICCV</b> 2019 <font color="red"><b>(Oral)</b></font></a>. [<a href= "http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Wavelet_Domain_Style_Transfer_for_an_Effective_Perception-Distortion_Tradeoff_in_ICCV_2019_paper.pdf">Paper</a>] [<a href="https://github.com/cindydeng1991/Wavelet-Domain-Style-Transfer-for-an-Effective-Perception-distortion-Tradeoff-in-Single-Image-Super-">Code</a>] </li>
<li>One paper is accepted to <b>IEEE T-PAMI</b>. [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855019">Paper</a>] [<a href="https://github.com/RyanXingQL/MFQEv2.0">Code</a>] </li>
<li>I am the <b>Winner of <a href= "https://threeminutethesis.uq.edu.au/">Three Minute Thesis Competition</a></b> at <b>IEEE ICME</b> 2019. [<a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Certificate</a>]</li>

</ul> 

<a id="publications" class="achor"></a>
<h2>Selected Publications</h2>

<table class="imgtable">

<tr>
<td><img class="proj_thumb" src="./papers/ALVC.PNG" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Advancing Learned Video Compression with In-loop Frame Prediction</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Radu Timofte and Luc Van Gool.<br>
IEEE Transactions on Circuits and Systems for Video Technology</i> (<b>T-CSVT</b>), 2023. <br>
[<a href= "https://ieeexplore.ieee.org/abstract/document/9950550">Paper</a>] [<a href= "https://github.com/RenYang-home/ALVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/MASIC.JPG" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">MASIC: Deep Mask Stereo Image Compression</p>
<p class="pub_author">Xin Deng,&nbsp;Yufan Deng,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Wenzhe Yang,&nbsp;Radu Timofte and Mai Xu.<br>
IEEE Transactions on Circuits and Systems for Video Technology</i> (<b>T-CSVT</b>), 2023. <br>
[<a href= "https://ieeexplore.ieee.org/abstract/document/10061473">Paper</a>] [<a href= "https://github.com/eecoder-dyf/MASIC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ECCV.jpg" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Implicit Neural Representations for Image Compression</p>
<p class="pub_author">Yannick Str端mpler,&nbsp;Janis Postels,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Luc van Gool and Federico Tombari.<br>
European Conference on Computer Vision</i> (<b>ECCV</b>), 2022. <br> 
[<a href= "https://arxiv.org/abs/2112.04267">Paper</a>] [<a href= "https://github.com/YannickStruempler/inr_based_compression">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/IJCAI.JPG" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Perceptual Learned Video Compression with Recurrent Conditional GAN</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Radu Timofte and Luc Van Gool.<br>
International Joint Conference on Artificial Intelligence</i> (<b>IJCAI</b>), 2022. <font color="red"><b>(Oral)</b></font> <br> 
[<a href= "https://arxiv.org/abs/2109.03082">Paper</a>] [<a href= "https://github.com/RenYang-home/PLVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/AIM.PNG" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">AIM 2022 Challenge on Super-Resolution of Compressed Image and Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u> and Radu Timofte.<br>
This challenge is a part of the <a href= "https://data.vision.ee.ethz.ch/cvl/aim22/">AIM workshop</a> in conjunction with <b>ECCV 2022</b>. <br> 
[<a href= "https://github.com/RenYang-home/AIM22_CompressSR">Homepage</a>] [<a href= "https://arxiv.org/abs/2208.11184">Report</a>] 
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/NTIRE_22.JPG" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">NTIRE 2022 Challenge on Super-Resolution and Quality Enhancement of Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u> and Radu Timofte.<br>
This challenge is a part of the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire22/">NTIRE workshop</a> in conjunction with <b>CVPR 2022</b>. <br> 
[<a href= "https://github.com/RenYang-home/NTIRE22_VEnh_SR">Homepage</a>] [<a href= "http://arxiv.org/abs/2204.09314">Report</a>] 
</p> </td>
</tr>
  
<tr>
<td><img class="proj_thumb" src="./papers/NTIRE_21.png" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">NTIRE 2021 Challenge on Quality Enhancement of Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u> and Radu Timofte.<br>
This challenge is a part of the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">NTIRE workshop</a> in conjunction with <b>CVPR 2021</b>. <br> 
[<a href= "https://github.com/RenYang-home/NTIRE21_VEnh">Homepage</a>] [<a href= "https://arxiv.org/abs/2104.10782">Dataset report</a>] [<a href= "https://arxiv.org/abs/2104.10781">Methods report</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/CVPR2021.png" alt=""/>&nbsp; </td>
<td>
<p class="pub_title">Deep Homography for Efficient Stereo Image Compression</p>
<p class="pub_author">Xin Deng,&nbsp;Wenzhe Yang,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Enpeng Liu,&nbsp;Qianhan Feng and Radu Timofte.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2021. <font color="red"><b>(Oral)</b></font> <br> 
[<a href= "http://buaamc2.net/pdf/cvpr21hesic.pdf">Paper</a>] [<a href= "https://github.com/ywz978020607/HESIC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/JSTSP.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning for Video Compression with Recurrent Auto-Encoder and Recurrent Probability Model</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Fabian Mentzer,&nbsp;Luc Van Gool and Radu Timofte.<br>
IEEE Journal of Selected Topics in Signal Processing</i> (<b>J-STSP</b>), 2021. <br> 
[<a href= "https://ieeexplore.ieee.org/abstract/document/9288876">Paper</a>] [<a href= "https://github.com/RenYang-home/RLVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/AIM20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning to Improve Image Compression without Changing the Standard Decoder</p>
<p class="pub_author">Yannick Str端mpler,&nbsp;<u><b>Ren Yang</b></u> and Radu Timofte.<br>
European Conference on Computer Vision Workshops</i> (<b>ECCVW</b>), 2020. <br> 
[<a href= "https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Paper</a>] [<a href="https://github.com/YannickStruempler/LearnedJPEG">Code</a>]
</p> </td>
</tr>
  
<tr>
<td><img class="proj_thumb" src="./papers/CVPR20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Learning for Video Compression with Hierarchical Quality and Recurrent Enhancement</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Fabian Mentzer,&nbsp;Luc Van Gool and Radu Timofte.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2020. <br> 
[<a href= "http://arxiv.org/abs/2003.01966">Paper</a>] [<a href= "https://github.com/RenYang-home/HLVC">Code</a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/TIP20.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Understanding and Predicting the Memorability of Outdoor Natural Scenes</p>
<p class="pub_author">Jiaxin Lu,&nbsp;Mai Xu,&nbsp;<u><b>Ren Yang</b></u> and Zulin Wang.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2020. <br> 
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9025769">Paper</a>] [<a href= "https://github.com/RenYang-home/Natural-Scene-Memorability">Code</a>] [<a href= "https://github.com/JiaxinLu-home/Natural-Scene-Memorability-Dataset">Dataset</a>] [<a href= "https://dl.acm.org/doi/pdf/10.1145/3267799.3267802">Conference paper (EE-USAD 2018) <font color="red"><b>(Oral)</b></font></a>]
</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ICCV19.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Wavelet Domain Style Transfer for an Effective Perception-distortion Tradeoff in Single Image Super-Resolution</p>
<p class="pub_author">Xin Deng,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Mai Xu and Pier Luigi Dragotti.<br>
IEEE International Conference on Computer Vision</i> (<b>ICCV</b>), 2019. <font color="red"><b>(Oral)</b></font><br>
[<a href= "http://openaccess.thecvf.com/content_ICCV_2019/papers/Deng_Wavelet_Domain_Style_Transfer_for_an_Effective_Perception-Distortion_Tradeoff_in_ICCV_2019_paper.pdf">Paper</a>] [<a href="https://github.com/cindydeng1991/Wavelet-Domain-Style-Transfer-for-an-Effective-Perception-distortion-Tradeoff-in-Single-Image-Super-">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/ICME19.png" alt=""/>&nbsp;</td>
<td>
<p class="pub_title">Quality-Gated Convolutional LSTM for Enhancing Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Xiaoyan Sun,&nbsp;Mai Xu and Wenjun Zeng.<br>
IEEE International Conference on Multimedia and Expo</i> (<b>ICME</b>), 2019. <font color="red"><b>(Oral)</b></font><br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8784864">Paper</a>] [<a href="https://github.com/ryangchn/QG-ConvLSTM">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/PAMI19.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video</p>
<p class="pub_author">Zhengyu Guan,&nbsp;Qunliang Xing,&nbsp;Mai Xu,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Tie Liu and Zulin Wang.<br>
IEEE Transactions on Pattern Analysis and Machine Intelligence</i> (<b>T-PAMI</b>), 2019. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8855019">Paper</a>] [<a href="https://github.com/RyanXingQL/MFQEv2.0">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/DCC19.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">A Deep Learning Approach for Multi-Frame In-Loop Filter of HEVC</p>
<p class="pub_author">Tianyi Li,&nbsp;Mai Xu,&nbsp;Ce Zhu,&nbsp;<u><b>Ren Yang</b></u>,&nbsp;Zulin Wang and Zhenyu Guan.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2019. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8736997">Paper</a>] [<a href="https://github.com/tianyili2017/MultiFrame-InLoop-Filter">Code</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8712730">Conference paper (DCC 2019) <font color="red"><b>(Oral)</b></font></a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/CVPR18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Multi-Frame Quality Enhancement for Compressed Video</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu, &nbsp;Zulin Wang and Tianyi Li.<br>
IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> (<b>CVPR</b>), 2018. <br>
[<a href= "http://openaccess.thecvf.com/content_cvpr_2018/papers/Yang_Multi-Frame_Quality_Enhancement_CVPR_2018_paper.pdf">Paper</a>] [<a href="https://github.com/ryangBUAA/MFQE">Code</a>] </p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/TIP18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Reducing Complexity of HEVC: A Deep Learning Approach</p>
<p class="pub_author">Mai Xu,&nbsp;Tianyi Li,&nbsp;Zulin Wang,&nbsp;Xin Deng,&nbsp;<u><b>Ren Yang</b></u> and Zhenyu Guan.<br>
IEEE Transactions on Image Processing</i> (<b>T-IP</b>), 2018. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8384310">Paper</a>] [<a href="https://github.com/tianyili2017/HEVC-Complexity-Reduction">Code</a>]</p> </td>
</tr>

<tr>
<td><img class="proj_thumb" src="./papers/CSVT18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Enhancing Quality for HEVC Compressed Videos</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Tie Liu,&nbsp;Zulin Wang and Zhenyu Guan.<br>
IEEE Transactions on Circuits and Systems for Video Technology</i> (<b>T-CSVT</b>), 2018. <br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8450025">Paper</a>] [<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019299">Conference paper (ICME 2017) <font color="red"><b>(Oral)</b></font></a>]</p> </td>
</tr>

<!-- <tr>
<td><img class="proj_thumb" src="./papers/ICME17.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Decoder-side HEVC quality enhancement with scalable convolutional neural network</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu and Zulin Wang.<br>
IEEE International Conference on Multimedia and Expo</i> (<b>ICME</b>), 2017. <font color="red"><b>(Oral)</b></font><br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8019299">Paper</a>]</p> </td>
</tr> -->

<tr>
<td><img class="proj_thumb" src="./papers/TBC18.png" alt="" />&nbsp;</td>
<td>
<p class="pub_title">Saliency-Guided Complexity Control for HEVC Decoding</p>
<p class="pub_author"><u><b>Ren Yang</b></u>,&nbsp;Mai Xu,&nbsp;Zulin Wang,&nbsp;Yiping Duan and Xiaoming Tao.<br>
IEEE Transactions on Broadcasting</i> (<b>T-BC</b>), 2018.<br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8281502">Paper</a>] [<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=7552864">Conference paper (ICME 2016)</a>]</p> </td>
</tr>

</table>

<a id="patents" class="achor"></a>
<h2>Patents</h2>
<ul>
<li><b>Multi-frame quality enhancement method and device for lossy compressed video</b> <br>
  WO2019154152A1 [<a href= "https://patents.google.com/patent/WO2019154152A1/en">Google Patent</a>] <br>
  US10965959B2, 2021 [<a href= "https://patents.google.com/patent/US10965959B2/en">Google Patent</a>] [<a href= "https://RenYang-home.github.io/papers/patent_US.pdf">Certificate</a>]<br>
  CN108307193B, 2018 [<a href= "https://patents.google.com/patent/CN108307193B/zh">Google Patent</a>] [<a href= "https://RenYang-home.github.io/papers/patent_MFQE.pdf">Certificate</a>]<br>
  Software copyright, 2020SR0472737, 2020 [<a href= "https://RenYang-home.github.io/papers/MFQE_software.pdf">Certificate</a>] <br>
</li>
</ul>
<ul>
<li><b>Deep learning method-based block segmentation coding complexity optimization method and device</b> <br>
  WO2019179523A1 [<a href= "https://patents.google.com/patent/WO2019179523A1/en">Google Patent</a>] <br>
  CN108495129B, 2019 [<a href= "https://patents.google.com/patent/CN108495129B/zh">Google Patent</a>] [<a href= "https://RenYang-home.github.io/papers/patent_CTU.pdf">Certificate</a>]<br>
   </li>
</ul>
<ul>
<li><b>A CNN-based method for image and video enhancement</b><br>
  CN107481209B, 2020 [<a href= "https://patents.google.com/patent/CN107481209A/zh">Google Patent</a>] [<a href= "https://RenYang-home.github.io/papers/patent_sfqe.pdf">Certificate</a>]<br>
  </li>
</ul>
<ul>
<li><b>A saliency-guided method for complexity control of HEVC decoding</b> <br>
  CN106210717B, 2017 [<a href= "https://patents.google.com/patent/CN106210717A/en?oq=%E4%B8%80%E7%A7%8D%E5%9F%BA%E4%BA%8E%E8%A7%86%E9%A2%91%E6%98%BE%E8%91%97%E6%80%A7%E7%9A%84HEVC%E8%A7%A3%E7%A0%81%E5%A4%8D%E6%9D%82%E5%BA%A6%E6%8E%A7%E5%88%B6%E6%96%B9%E6%B3%95">Google Patent</a>] [<a href= "https://RenYang-home.github.io/papers/patent_sgcc.pdf">Certificate</a>] <br>
  </li>
</ul>

<a id="awards" class="achor"></a>
<h2>Awards</h2>
<ul>
<li><b>Chinese Government Award for Outstanding Self-financed Students Abroad (10,000 USD)</b>. [<a href= "http://RenYang-home.github.io/papers/CSC.jpg">Certificate</a>]
<li><b>Winner of <a href= "https://threeminutethesis.uq.edu.au/">Three Minute Thesis Competition</a></b>, IEEE ICME 2019. [<a href= "https://RenYang-home.github.io/papers/ICMEaward.jpg">Certificate</a>]</li>
<li><b>2019 Outstanding Master Thesis Award</b> of <a href="https://www.cie-info.org.cn/">Chinese Institute of Elecronics</a>. [<a href= "https://www.cie.org.cn/list_43/3519.html">News</a>] [<a href= "https://RenYang-home.github.io/papers/CIE_master.jpg">Certificate</a>]</li>
<li><b>Award of Excellence</b> at Microsoft Research. [<a href= "https://RenYang-home.github.io/papers/MSRaward.jpg">Certificate</a>]</li>
<li><b>TOP 10</b> Graduate Students Award, Beihang University. [<a href= "https://RenYang-home.github.io/papers/Top10.jpg">Certificate</a>]</li>
<li><b>National Scholarship</b>, P.R. China. [<a href= "https://RenYang-home.github.io/papers/guojiang.jpg">Certificate</a>]</li>
</ul>

<!-- Tutorials -->
<a id="tutorials" class="anchor"></a>
<h2>Tutorials</h2> 
<ul>
<li>ACM MM 2021: Deep Learning for Visual Data Compression.
<li>CVPR 2021: Deep Learning for Visual Data Compression. [<a href= "https://guolu-home.github.io/cvpr21-tutorial">Tutorial homepage</a>]
<li>IEEE VCIP 2020: Learned Image and Video Compression with Deep Neural Networks. [<a href= "https://ieeexplore.ieee.org/abstract/document/9301828">Abstract</a>] [<a href= "http://RenYang-home.github.io/papers/VCIP_Tutorial.pdf">Slide</a>] [<a href= "https://www.polybox.ethz.ch/index.php/s/PSmRYBTyvljzkbm">Video record</a>]</li>
</ul>

<!-- Workshops -->
<a id="workshops" class="anchor"></a>
<h2>Workshops</h2> 
<ul>
<li>Co-organizer of the <a href= "https://cvlai.net/ntire/2023/">8th New Trends in Image Restoration and Enhancement (NTIRE) workshop</a> (CVPR 2023).
    <ul>
        
    </ul>
</li>
<li>Co-organizer of the <a href= "https://data.vision.ee.ethz.ch/cvl/aim22/">Advances in Image Manipulation (AIM) workshop</a> (ECCV 2022).
  <ul>
    <li>Organizer of the <a href="https://github.com/RenYang-home/AIM22_CompressSR">AIM 2022 Challenge on Super-Resolution of Compressed Image and Video</a> [<a href= "https://arxiv.org/abs/2208.11184">Report</a>]</li>
  </ul>
</li>
<li>Co-organizer of the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire22/">7th New Trends in Image Restoration and Enhancement (NTIRE) workshop</a> (CVPR 2022).
  <ul>
    <li>Organizer of the <a href= "https://github.com/RenYang-home/NTIRE22_VEnh_SR">NTIRE 2022 Challenge on Super-Resolution and Quality Enhancement of Compressed Video</a> [<a href= "https://arxiv.org/abs/2204.09314">Report</a>]</li>
  </ul>
</li>
<li>Co-organizer of the <a href= "https://data.vision.ee.ethz.ch/cvl/ntire21/">6th New Trends in Image Restoration and Enhancement (NTIRE) workshop</a> (CVPR 2021).
  <ul>
    <li>Organizer of the <a href= "https://github.com/RenYang-home/NTIRE21_VEnh">NTIRE 2021 Challenge on Quality Enhancement of Compressed Video</a> [<a href= "https://arxiv.org/abs/2104.10782">Dataset</a>] [<a href= "https://arxiv.org/abs/2104.10781">Methods</a>]</li>
  </ul>
</li>
</ul>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>

<p>Session Chair: </p>
<ul>
  <li>International Joint Conference on Artificial Intelligence (IJCAI 2022) [<a href= "http://RenYang-home.github.io/papers/session_chair.png">Program</a>]</li>
</ul>

<p>Senior Program Commitee (SPC) Member: </p>
<ul>
  <li>International Joint Conference on Artificial Intelligence (IJCAI 2021) [<a href= "http://RenYang-home.github.io/papers/IJCAI_SPC.pdf">Certificate</a>]</li>
</ul>

<p>Journal Reviewer: </p>
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (T-PAMI)</li>
<li>International Journal on Computer Vision (IJCV)</li>
<li>IEEE Transactions on Image Processing (T-IP)</li>
<li>IEEE Journal of Selected Topics in Signal Processing (J-STSP)</li>
<li>IEEE Transactions on Multimedia (T-MM)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (T-CSVT)</li>
<li>IEEE Transactions on Emerging Topics in Computational Intelligence (T-ETCI)</li>
<li>IEEE Open Journal of Circuits and Systems (OJ-CAS)</li> 
<li>IEEE Signal Processing Letters (SPL)</li> 
<li>IEEE Access</li>
<li>Elsevier's Signal Processing: Image Communication</li>
<li>Elsevier's Neurocomputing</li>
<li>Hindawi's Advances in Multimedia</li>

</ul>
<p>Conference Reviewer/Program Commitee (PC) Member: </p>
<ul>
<li>Annual Conference on Neural Information Processing Systems (NeurIPS 2022)</li>
<li>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR 2021/2022/2023)</li>
<li>IEEE International Conference on Computer Vision (ICCV 2021/2023)</li>
<li>European Conference on Computer Vision (ECCV 2020/2022)</li>
<li>International Conference on Learning Representations (ICLR 2022/2023)</li>
<li>International Conference on Machine Learning (ICML 2023)</li>
<li>AAAI Conference on Artificial Intelligence (AAAI 2022/2023)</li>
<li>International Joint Conference on Artificial Intelligence (IJCAI 2021/2022)</li>
<li>Asian Conference on Computer Vision (ACCV 2020)</li>
<li>IEEE Visual Communications and Image Processing (VCIP 2021/2022) </li>
<li>IEEE/CIC International Conference on Communications in China (ICCC 2018)</li>
</ul>

<!-- Teaching and Supervision-->
<a id="teaching" class="anchor"></a>
<h2>Teaching and Supervision</h2> 
<ul>
<li>Supervisor: <a href="https://arxiv.org/abs/2112.04267">Master's Thesis</a> on learned image compression, ETH Zurich (Spring 2021) </li>
<li>Supervisor: <a href="https://link.springer.com/chapter/10.1007/978-3-030-66823-5_12">Master's Semester Project</a> on learned image compression, ETH Zurich (Spring 2020) </li>
<li>Teaching Assistant: Digital Image Processing, Beihang University (Spring 2017) </li>
</ul>

<div id="footer">
</div>

</div>
</div>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/8.js?i=5y5sm64rjm3&amp;m=0&amp;c=ff0000&amp;cr1=ff0000&amp;f=arial&amp;l=33" async="async"></script>
</body>
</html>
